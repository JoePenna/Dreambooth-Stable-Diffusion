{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load repo (if needed)\n",
    "!git clone https://github.com/JoePenna/Dreambooth-Stable-Diffusion\n",
    "%cd Dreambooth-Stable-Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qeTrc2vOeiNh"
   },
   "outputs": [],
   "source": [
    "# BUILD ENV\n",
    "!pip install omegaconf\n",
    "!pip install einops\n",
    "!pip install pytorch-lightning==1.6.5\n",
    "!pip install test-tube\n",
    "!pip install transformers\n",
    "!pip install kornia\n",
    "!pip install -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers\n",
    "!pip install -e git+https://github.com/openai/CLIP.git@main#egg=clip\n",
    "!pip install setuptools==59.5.0\n",
    "!pip install pillow==9.0.1\n",
    "!pip install torchmetrics==0.6.0\n",
    "!pip install -e .\n",
    "!pip install protobuf==3.20.1\n",
    "!pip install gdown\n",
    "!pip install pydrive\n",
    "!pip install -qq diffusers[\"training\"]==0.3.0 transformers ftfy\n",
    "!pip install -qq \"ipywidgets>=7,<8\"\n",
    "!pip install huggingface_hub\n",
    "!pip install ipywidgets==7.7.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6tjx0HcjesFo"
   },
   "outputs": [],
   "source": [
    "# Hugging Face Login\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O15vMMhCevib"
   },
   "outputs": [],
   "source": [
    "# Download the 1.4 sd model\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from huggingface_hub import hf_hub_download\n",
    "downloaded_model_path = hf_hub_download(\n",
    " repo_id=\"CompVis/stable-diffusion-v-1-4-original\",\n",
    " filename=\"sd-v1-4.ckpt\",\n",
    " use_auth_token=True\n",
    ")\n",
    "\n",
    "# Move the sd-v1-4.ckpt to the root of this directory as \"model.ckpt\"\n",
    "actual_locations_of_model_blob = !readlink -f {downloaded_model_path}\n",
    "!mv {actual_locations_of_model_blob[-1]} model.ckpt\n",
    "clear_output()\n",
    "print(\"✅ model.ckpt successfully downloaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Regularization Images\n",
    "We’ve created the following image sets\n",
    "- `man_euler` - provided by Niko Pueringer (Corridor Digital) - euler @ 40 steps, CFG 7.5\n",
    "- `man_unsplash` - pictures from various photographers\n",
    "- `person_ddim`\n",
    "- `woman_ddim` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />\n",
    "- `blonde_woman` - provided by David Bielejeski - ddim @ 50 steps, CFG 10.0 <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N96aedTtfBjO"
   },
   "outputs": [],
   "source": [
    "dataset=\"person_ddim\"\n",
    "!git clone https://github.com/djbielejeski/Stable-Diffusion-Regularization-Images-{dataset}.git\n",
    "\n",
    "!mkdir -p regularization_images/{dataset}\n",
    "!mv -v Stable-Diffusion-Regularization-Images-{dataset}/{dataset}/*.* regularization_images/{dataset}\n",
    "\n",
    "# Create the training image directory\n",
    "!rm -rf training_images\n",
    "!mkdir -p training_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Images\n",
    "## Upload your training images\n",
    "WARNING: Be sure to upload an even amount of images, otherwise the training inexplicably stops at 1500 steps. <br />\n",
    "- 2-3 full body\n",
    "- 3-5 upper body\n",
    "- 5-12 close-up on face  <br /> <br />\n",
    "The images should be as close as possible to the kind of images you’re trying to make (most of the time, that means no selfies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7hmdOdOfGzs"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Tell the user what is going on\n",
    "training_images_file_paths = !find training_images/*\n",
    "if len(training_images_file_paths) == 0:\n",
    " print(\"❌ no training images found. Please upload images to training_images\")\n",
    "else:\n",
    " print(\"✅ \" + str(len(training_images_file_paths)) + \" training images found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2o_fFFvfxHi"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# This isn't used for training, just to help you remember what your trained into the model.\n",
    "project_name = \"project_name\"\n",
    "\n",
    "# MAX STEPS\n",
    "# How many steps do you want to train for?\n",
    "max_training_steps = 2000\n",
    "\n",
    "# Match class_word to the category of the regularization images you chose above.\n",
    "class_word = \"person\"\n",
    "\n",
    "# This is the unique token you are incorporating into the stable diffusion model.\n",
    "token = \"firstNameLastName\"\n",
    "reg_data_root = \"/workspace/Dreambooth-Stable-Diffusion/regularization_images/\" + dataset\n",
    "\n",
    "!rm -rf training_images/.ipynb_checkpoints\n",
    "!python \"main.py\" \\\n",
    " --base configs/stable-diffusion/v1-finetune_unfrozen.yaml \\\n",
    " -t \\\n",
    " --actual_resume \"model.ckpt\" \\\n",
    " --reg_data_root \"{reg_data_root}\" \\\n",
    " -n \"{project_name}\" \\\n",
    " --gpus 0, \\\n",
    " --data_root \"/workspace/Dreambooth-Stable-Diffusion/training_images\" \\\n",
    " --max_training_steps {max_training_steps} \\\n",
    " --class_word \"{class_word}\" \\\n",
    " --token \"{token}\" \\\n",
    " --no-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ll_ZIFNUulKJ"
   },
   "outputs": [],
   "source": [
    "# Copy and name the checkpoint file\n",
    "\n",
    "directory_paths = !ls -d logs/*\n",
    "last_checkpoint_file = directory_paths[-1] + \"/checkpoints/last.ckpt\"\n",
    "training_images = !find training_images/*\n",
    "date_string = !date +\"%Y-%m-%dT%H-%M-%S\"\n",
    "file_name = date_string[-1] + \"_\" + project_name + \"_\" + str(len(training_images)) + \"_training_images_\" +  str(max_training_steps) + \"_max_training_steps_\" + token + \"_token_\" + class_word + \"_class_word.ckpt\"\n",
    "\n",
    "file_name = file_name.replace(\" \", \"_\")\n",
    "\n",
    "!mkdir -p trained_models\n",
    "!mv \"{last_checkpoint_file}\" \"trained_models/{file_name}\"\n",
    "\n",
    "print(\"Download your trained model file from trained_models/\" + file_name + \" and use in your favorite Stable Diffusion repo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Optional - Upload to google drive\n",
    "* run the following commands in a new `terminal` in the `Dreambooth-Stable-Diffusion` directory\n",
    "* `chmod +x ./gdrive`\n",
    "* `./gdrive about`\n",
    "* `paste your token here after navigating to the link`\n",
    "* `./gdrive upload trained_models/{file_name.ckpt}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90ac5c",
   "metadata": {},
   "source": [
    "# Big Important Note!\n",
    "\n",
    "The way to use your token is `<token> <class>` ie `joepenna person` and not just `joepenna`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28d0139",
   "metadata": {},
   "source": [
    "## Generate Images With Your Trained Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = f\"/workspace/Dreambooth-Stable-Diffusion/trained_models/{file_name}\" \n",
    "prompt =  f\"{token} {class_word} person as a masterpiece portrait painting by John Singer Sargent in the style of Rembrandt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ddb03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/stable_txt2img.py \\\n",
    " --ddim_eta 0.0 \\\n",
    " --n_samples 4 \\\n",
    " --n_iter 1 \\\n",
    " --scale 7.0 \\\n",
    " --ddim_steps 50 \\\n",
    " --ckpt \"{model}\" \\\n",
    " --prompt \"{prompt}\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
